{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learning to Ignore: Long Document Coreference with Bounded Memory Neural Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giochen/google_code/blob/main/Learning_to_Ignore_Long_Document_Coreference_with_Bounded_Memory_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nxCjSC0R6UH"
      },
      "source": [
        "This colab notebook performs inference with a model trained on LitBank described in our EMNLP 2020 paper [Learning to Ignore: Long Document Coreference with Bounded Memory Neural Networks](https://www.aclweb.org/anthology/2020.emnlp-main.685.pdf)\n",
        "\n",
        "### Clone Github repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2svNmateR5Vn"
      },
      "source": [
        "%%capture\n",
        "! git clone https://github.com/shtoshni92/long-doc-coref.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN_Huv6-QKZ0"
      },
      "source": [
        "### Install Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycSXQitdSbPp"
      },
      "source": [
        "%%capture\n",
        "! pip install torch==1.6.0\n",
        "! pip install transformers==4.2.2\n",
        "! pip install scipy==1.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D24Y8HPCQMQm"
      },
      "source": [
        "### Download Pretrained Models\n",
        "\n",
        "The pretrained models are released [here](https://drive.google.com/drive/folders/1UFhkrlBP-O2MeaxVygZcuP9RWuglOTmN?usp=sharing). In this example we will download one of the LitBank models, specifically the litbank_lbmem_val_3_dev_77.3 one - A LB-MEM model with 20 cells which is trained on cross validation split 3 of LitBank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyeMJUJvQXea",
        "outputId": "3a702341-1c7f-419b-ed2b-f15807ee50bb"
      },
      "source": [
        "!gdown --id 1PKlFab387j_1GnYA9E4lq-8nQ9csEeAL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PKlFab387j_1GnYA9E4lq-8nQ9csEeAL\n",
            "To: /content/model.pth\n",
            "187MB [00:01, 119MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odbMTOymRreq",
        "outputId": "6984c183-381c-4053-a984-834022f5e9c9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mlong-doc-coref\u001b[0m/  model.pth  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCHke-lIR0i6"
      },
      "source": [
        "### Inference on Sample Text\n",
        "\n",
        "Now that we have the code and the pretrained model, time to test the model on some sample data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPoL9LyQaj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71575690-073a-4ba4-96af-4587285a7ed5"
      },
      "source": [
        "import sys\n",
        "sys.path.append('long-doc-coref/src')\n",
        "\n",
        "# This will also download the SpanBERT model finetuned for Coreference (by Joshi et al, 2020) from Huggingface\n",
        "from inference.inference import Inference\n",
        "inference_model = Inference(\"model.pth\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'base_data_dir': '/share/data/speech/shtoshni/research/litbank_coref/data', 'base_model_dir': '/share/data/speech/shtoshni/research/litbank_coref/models', 'dataset': 'litbank', 'conll_scorer': '../lrec2020-coref/reference-coreference-scorers/scorer.pl', 'model_size': 'large', 'doc_enc': 'overlap', 'pretrained_bert_dir': '/share/data/speech/shtoshni/resources', 'max_segment_len': 512, 'max_span_width': 20, 'ment_emb': 'attn', 'top_span_ratio': 0.3, 'mem_type': 'learned', 'num_cells': 20, 'mlp_size': 3000, 'mlp_depth': 1, 'entity_rep': 'wt_avg', 'emb_size': 20, 'cross_val_split': 3, 'new_ent_wt': 2.0, 'num_train_docs': None, 'max_training_segments': 5, 'sample_invalid': 0.25, 'dropout_rate': 0.3, 'label_smoothing_wt': 0.0, 'max_epochs': 25, 'seed': 0, 'init_lr': 0.0002, 'no_singletons': False, 'eval': False, 'slurm_id': '6077327_172', 'model_dir': '/share/data/speech/shtoshni/research/litbank_coref/models/coref_aff65ce80c7eefcce3c2451b554e1e68', 'best_model_dir': '/share/data/speech/shtoshni/research/litbank_coref/models/coref_aff65ce80c7eefcce3c2451b554e1e68/best_models', 'data_dir': '/share/data/speech/shtoshni/research/litbank_coref/data/litbank/overlap/3', 'conll_data_dir': '/share/data/speech/shtoshni/research/litbank_coref/data/litbank/conll/3', 'pretrained_mention_model': '/share/data/speech/shtoshni/research/litbank_coref/models/ment_litbank_width_20_mlp_3000_model_large_emb_attn_type_spanbert_enc_overlap_segment_512_split_3/best_models/model.pth'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PuZyctVZFqH"
      },
      "source": [
        "### Sample Doc\n",
        "\n",
        "Here's an excerpt from [The War of the Worlds](https://en.wikipedia.org/wiki/The_War_of_the_Worlds). The LitBank annotations for the doc are visualized [here](https://ttic.uchicago.edu/~shtoshni/coref/litbank_html/36_the_war_of_the_worlds.html) -- the excerpt is just the prefix (The doc was part of the dev set for the LitBank model we are using).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1YH31lxSeZ1"
      },
      "source": [
        "doc = \"\"\"\n",
        "    BOOK ONE THE COMING OF THE MARTIANS CHAPTER ONE THE EVE OF THE WAR No one would have believed in the last years of the nineteenth century that this world was being watched keenly and closely by intelligences greater than man 's and yet as mortal as his own ; that as men busied themselves about their various concerns they were scrutinised and studied , perhaps almost as narrowly as a man with a microscope might scrutinise the transient creatures that swarm and multiply in a drop of water .\n",
        "    With infinite complacency men went to and fro over this globe about their little affairs , serene in their assurance of their empire over matter .\n",
        "    It is possible that the infusoria under the microscope do the same .\n",
        "    No one gave a thought to the older worlds of space as sources of human danger , or thought of them only to dismiss the idea of life upon them as impossible or improbable .\n",
        "    It is curious to recall some of the mental habits of those departed days .\n",
        "    At most terrestrial men fancied there might be other men upon Mars , perhaps inferior to themselves and ready to welcome a missionary enterprise .\n",
        "    Yet across the gulf of space , minds that are to our minds as ours are to those of the beasts that perish , intellects vast and cool and unsympathetic , regarded this earth with envious eyes , and slowly and surely drew their plans against us .\n",
        "    And early in the twentieth century came the great disillusionment .\n",
        "    The planet Mars , I scarcely need remind the reader , revolves about the sun at a mean distance of 140,000,000 miles , and the light and heat it receives from the sun is barely half of that received by this world .\n",
        "    It must be , if the nebular hypothesis has any truth , older than our world ; and long before this earth ceased to be molten , life upon its surface must have begun its course .\n",
        "    The fact that it is scarcely one seventh of the volume of the earth must have accelerated its cooling to the temperature at which life could begin .\n",
        "    It has air and water and all that is necessary for the support of animated existence .\n",
        "    Yet so vain is man , and so blinded by his vanity , that no writer , up to the very end of the nineteenth century , expressed any idea that intelligent life might have developed there far , or indeed at all , beyond its earthly level .\n",
        "    Nor was it generally understood that since Mars is older than our earth , with scarcely a quarter of the superficial area and remoter from the sun , it necessarily follows that it is not only more distant from time 's beginning but nearer its end .\n",
        "    The secular cooling that must someday overtake our planet has already gone far indeed with our neighbour .\n",
        "    Its physical condition is still largely a mystery , but we know now that even in its equatorial region the midday temperature barely approaches that of our coldest winter .\n",
        "    Its air is much more attenuated than ours , its oceans have shrunk until they cover but a third of its surface , and as its slow seasons change huge snowcaps gather and melt about either pole and periodically inundate its temperate zones .\n",
        "    That last stage of exhaustion , which to us is still incredibly remote , has become a present-day problem for the inhabitants of Mars .\n",
        "    \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO7tonLZSru8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b179f361-d4a4-438a-80f7-fa09acf89fb6"
      },
      "source": [
        "output = inference_model.perform_coreference(doc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0X2g7gYV256",
        "outputId": "11968a08-6181-4b65-fd24-1714dfeed76c"
      },
      "source": [
        "for cluster in output[\"clusters\"]:\n",
        "  print(cluster)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[((9, 13), 'THE EVE OF THE WAR')]\n",
            "[((5, 6), 'THE MARTIANS')]\n",
            "[((71, 75), 'a man with a microscope')]\n",
            "[((12, 13), 'THE WAR')]\n",
            "[((14, 15), 'No one')]\n",
            "[((181, 183), 'most terrestrial men')]\n",
            "[((407, 408), 'no writer')]\n",
            "[((397, 397), 'man'), ((403, 403), 'his')]\n",
            "[((547, 548), 'its oceans'), ((552, 552), 'they')]\n",
            "[((578, 580), 'its temperate zones')]\n",
            "[((28, 29), 'this world'), ((100, 101), 'this globe'), ((237, 238), 'this earth'), ((308, 309), 'this world'), ((325, 326), 'our world'), ((331, 332), 'this earth'), ((360, 361), 'the earth'), ((453, 454), 'our earth')]\n",
            "[((40, 40), 'man'), ((48, 48), 'his')]\n",
            "[((53, 53), 'men'), ((55, 55), 'themselves'), ((57, 57), 'their'), ((60, 60), 'they'), ((94, 94), 'men'), ((103, 103), 'their'), ((109, 109), 'their'), ((112, 112), 'their'), ((248, 248), 'their')]\n",
            "[((524, 526), 'its equatorial region')]\n",
            "[((130, 131), 'No one')]\n",
            "[((136, 140), 'the older worlds of space'), ((150, 150), 'them'), ((159, 159), 'them')]\n",
            "[((604, 607), 'the inhabitants of Mars')]\n",
            "[((182, 183), 'terrestrial men'), ((196, 196), 'themselves')]\n",
            "[((188, 189), 'other men')]\n",
            "[((188, 203), 'other men upon Mars, perhaps inferior to themselves and ready to welcome a missionary enterprise')]\n",
            "[((191, 191), 'Mars'), ((264, 266), 'The planet Mars'), ((296, 296), 'it'), ((311, 311), 'It'), ((340, 340), 'its'), ((351, 351), 'it'), ((365, 365), 'its'), ((376, 376), 'It'), ((429, 429), 'there'), ((438, 438), 'its'), ((449, 449), 'Mars'), ((474, 474), 'it'), ((505, 506), 'our neighbour'), ((508, 508), 'Its'), ((524, 524), 'its'), ((538, 538), 'Its'), ((547, 547), 'its'), ((558, 558), 'its'), ((563, 563), 'its'), ((578, 578), 'its'), ((607, 607), 'Mars')]\n",
            "[((216, 216), 'our'), ((219, 219), 'ours'), ((251, 251), 'us'), ((325, 325), 'our'), ((453, 453), 'our'), ((497, 497), 'our'), ((505, 505), 'our'), ((518, 518), 'we'), ((534, 534), 'our'), ((545, 545), 'ours'), ((590, 590), 'us')]\n",
            "[((229, 234), 'intellects vast and cool and unsympathetic')]\n",
            "[((268, 268), 'I')]\n",
            "[((272, 273), 'the reader')]\n",
            "[((380, 380), 'water')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MfdoUsUbAjx"
      },
      "source": [
        "#### Remove Singletons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4BdbHAXbKXf",
        "outputId": "14cf7ddf-52ed-427d-f4ed-1209c3a00f89"
      },
      "source": [
        "for cluster in output[\"clusters\"]:\n",
        "  if len(cluster) > 1:\n",
        "    print(cluster)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[((397, 397), 'man'), ((403, 403), 'his')]\n",
            "[((547, 548), 'its oceans'), ((552, 552), 'they')]\n",
            "[((28, 29), 'this world'), ((100, 101), 'this globe'), ((237, 238), 'this earth'), ((308, 309), 'this world'), ((325, 326), 'our world'), ((331, 332), 'this earth'), ((360, 361), 'the earth'), ((453, 454), 'our earth')]\n",
            "[((40, 40), 'man'), ((48, 48), 'his')]\n",
            "[((53, 53), 'men'), ((55, 55), 'themselves'), ((57, 57), 'their'), ((60, 60), 'they'), ((94, 94), 'men'), ((103, 103), 'their'), ((109, 109), 'their'), ((112, 112), 'their'), ((248, 248), 'their')]\n",
            "[((136, 140), 'the older worlds of space'), ((150, 150), 'them'), ((159, 159), 'them')]\n",
            "[((182, 183), 'terrestrial men'), ((196, 196), 'themselves')]\n",
            "[((191, 191), 'Mars'), ((264, 266), 'The planet Mars'), ((296, 296), 'it'), ((311, 311), 'It'), ((340, 340), 'its'), ((351, 351), 'it'), ((365, 365), 'its'), ((376, 376), 'It'), ((429, 429), 'there'), ((438, 438), 'its'), ((449, 449), 'Mars'), ((474, 474), 'it'), ((505, 506), 'our neighbour'), ((508, 508), 'Its'), ((524, 524), 'its'), ((538, 538), 'Its'), ((547, 547), 'its'), ((558, 558), 'its'), ((563, 563), 'its'), ((578, 578), 'its'), ((607, 607), 'Mars')]\n",
            "[((216, 216), 'our'), ((219, 219), 'ours'), ((251, 251), 'us'), ((325, 325), 'our'), ((453, 453), 'our'), ((497, 497), 'our'), ((505, 505), 'our'), ((518, 518), 'we'), ((534, 534), 'our'), ((545, 545), 'ours'), ((590, 590), 'us')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}